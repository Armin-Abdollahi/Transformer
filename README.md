# Transformer

---
Implementing the Vision Transformer (ViT) model for image classification.

**Introduction:**

This example implements the Vision Transformer (ViT) model for image classification, and demonstrates it on the CIFAR-100 dataset. The ViT model applies the Transformer architecture with self-attention to sequences of image patches, without using convolution layers.

---

![Transformer](https://github.com/Armin-Abdollahi/Transformer/assets/103449830/8db83736-b5c6-40eb-8cdc-6bf9d98b49ad)
